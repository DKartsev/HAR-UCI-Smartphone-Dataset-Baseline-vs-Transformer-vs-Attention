# Human Activity Recognition (UCI HAR)  
## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ baseline –∏ Transformer-–ø–æ–¥—Ö–æ–¥–æ–≤ –≤ —É—Å–ª–æ–≤–∏—è—Ö Colab Free

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](#)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.x-ee4c2c.svg)](#)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.x-f7931e.svg)](#)
[![Platform](https://img.shields.io/badge/Platform-Google%20Colab-F9AB00.svg)](#)
[![Dataset](https://img.shields.io/badge/Dataset-UCI%20HAR-4caf50.svg)](#)

---

## –û –ø—Ä–æ–µ–∫—Ç–µ

–ü—Ä–æ–µ–∫—Ç –ø–æ—Å–≤—è—â—ë–Ω –∑–∞–¥–∞—á–µ **—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (HAR)** –ø–æ –∏–Ω–µ—Ä—Ü–∏–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º —Å–º–∞—Ä—Ç—Ñ–æ–Ω–∞ (–∞–∫—Å–µ–ª–µ—Ä–æ–º–µ—Ç—Ä + –≥–∏—Ä–æ—Å–∫–æ–ø) –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ **UCI HAR**.  
–¶–µ–ª—å ‚Äî –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –Ω–∞—É—á–Ω–æ-–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–±–æ—Ç—ã –∏ —Å—Ä–∞–≤–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–º–µ–π—Å—Ç–≤ –º–æ–¥–µ–ª–µ–π:

1. **Baseline (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π ML):** Logistic Regression –Ω–∞ hand-crafted –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö (561 feature).
2. **–ë–∞–∑–æ–≤—ã–π Transformer:** –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—ã—Ä—ã—Ö –æ–∫–æ–Ω `128 x 9`.
3. **–£–ª—É—á—à–µ–Ω–Ω—ã–π Transformer:** —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è.
4. **SE-Transformer:** –∫–∞–Ω–∞–ª–æ–≤–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ (Squeeze-and-Excitation style) –ø–µ—Ä–µ–¥ Transformer.
5. **Windowed Transformer:** –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ –≤–Ω–∏–º–∞–Ω–∏—è –≤–æ –≤—Ä–µ–º–µ–Ω–∏).

–ü—Ä–æ–µ–∫—Ç —Å–¥–µ–ª–∞–Ω —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞:
- –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å,
- –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª –≤–∞–ª–∏–¥–∞—Ü–∏–∏/—Ç–µ—Å—Ç–∞,
- –æ–±—ä—è—Å–Ω–∏–º—ã–µ –≤—ã–≤–æ–¥—ã,
- –∑–∞–ø—É—Å–∫ –≤ **Google Colab Free**.

---

## –ó–∞–¥–∞—á–∞

–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å 6 –≤–∏–¥–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:

- `WALKING`
- `WALKING_UPSTAIRS`
- `WALKING_DOWNSTAIRS`
- `SITTING`
- `STANDING`
- `LAYING`

–ü–æ –¥–∞–Ω–Ω—ã–º –¥–∞—Ç—á–∏–∫–æ–≤ —Å–º–∞—Ä—Ç—Ñ–æ–Ω–∞ –≤ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–Ω–∞—Ö –¥–ª–∏–Ω—ã 128.

---

## –î–∞—Ç–∞—Å–µ—Ç

- **–ò—Å—Ç–æ—á–Ω–∏–∫:** UCI Human Activity Recognition Using Smartphones
- **–°—ã—Ä—ã–µ –≤—Ö–æ–¥—ã –¥–ª—è Transformer:** —Ç–µ–Ω–∑–æ—Ä –æ–∫–Ω–∞ `T x C = 128 x 9`
- **Baseline-–ø—Ä–∏–∑–Ω–∞–∫–∏:** 561 engineered feature (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç UCI HAR)

### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (–∏–∑ EDA)

| Activity | Train Count | Test Count |
|---|---:|---:|
| WALKING | 1226 | 496 |
| WALKING_UPSTAIRS | 1073 | 471 |
| WALKING_DOWNSTAIRS | 986 | 420 |
| SITTING | 1286 | 491 |
| STANDING | 1374 | 532 |
| LAYING | 1407 | 537 |

---

##  –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω

### –ú–µ—Ç—Ä–∏–∫–∏
- Accuracy
- Macro Precision
- Macro Recall
- Macro F1 (–∫–ª—é—á–µ–≤–∞—è)
- Confusion Matrix
- Classification Report
- –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (—Å–µ–∫)

### –ü—Ä–∏–Ω—Ü–∏–ø—ã –æ—Ü–µ–Ω–∫–∏
- –û—Ç–¥–µ–ª—å–Ω—ã–π test set.
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–µ –∑–∞–¥–∞—á–∏.
- –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø–∞—Ä –∫–ª–∞—Å—Å–æ–≤.
- –§–∏–∫—Å–∞—Ü–∏—è `seed` –∏ –¥–∞–º–ø –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏.

---

##  –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã

### 1) Baseline: Logistic Regression (561 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –ª–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ hand-crafted –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö UCI HAR.

**–ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (test):**
- Accuracy: **0.9539**
- Macro F1: **0.9538**
- Macro Precision: **0.9569**
- Macro Recall: **0.9526**
- Train Time: **4.71 s**

---

### 2) –ë–∞–∑–æ–≤—ã–π Transformer (—Å—ã—Ä—ã–µ –æ–∫–Ω–∞ 128x9)
–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π encoder-–ø–æ–¥—Ö–æ–¥:
- Linear projection `9 -> d_model`
- Positional Encoding
- Transformer Encoder
- Mean pooling –ø–æ –≤—Ä–µ–º–µ–Ω–∏
- Classification head

**–ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (test):**
- Accuracy: **0.8924**
- Macro F1: **0.8920**
- Macro Precision: **0.8919**
- Macro Recall: **0.8935**
- Train Time: **29.95 s**

---

### 3) Improved Transformer
–£—Å–∏–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è Transformer —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–∏—ë–º–∞–º–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏/–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏  
(–±–æ–ª—å—à–µ —ë–º–∫–æ—Å—Ç—å, attention pooling/CLS-–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, —É–ª—É—á—à–µ–Ω–Ω—ã–π schedule –∏ —Ç.–¥.).

**–ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (test):**
- Accuracy: **0.9046**
- Macro F1: **0.9044**
- Macro Precision: **0.9052**
- Macro Recall: **0.9057**
- Train Time: **158.52 s**

---

### 4) SE Transformer (–∫–∞–Ω–∞–ª–æ–≤–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ)
–î–æ–±–∞–≤–ª–µ–Ω –±–ª–æ–∫ **Channel SE** –ø–µ—Ä–µ–¥ Transformer-—ç–Ω–∫–æ–¥–µ—Ä–æ–º –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–µ—Ä–µ-–≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤.

**–ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (test):**
- Accuracy: **0.9009**
- Macro F1: **0.9001**
- Macro Precision: **0.9013**
- Macro Recall: **0.9011**
- Train Time: **200.69 s**

---

### 5) Windowed Transformer (–ª–æ–∫–∞–ª—å–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ)
–õ–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è self-attention –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –æ–∫–Ω–∞–º (windowed attention) –¥–ª—è –∞–∫—Ü–µ–Ω—Ç–∞ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö –¥–≤–∏–∂–µ–Ω–∏—è.

**–ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (test):**
- Accuracy: **0.8975**
- Macro F1: **0.8973**
- Macro Precision: **0.8974**
- Macro Recall: **0.8984**
- Train Time: **182.48 s**

---

## üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

| Model | Accuracy | Macro F1 | Macro Precision | Macro Recall | Train Time (s) |
|---|---:|---:|---:|---:|---:|
| Logistic Regression (561 features) | **0.9539** | **0.9538** | **0.9569** | **0.9526** | **4.71** |
| Transformer (raw 128x9) | 0.8924 | 0.8920 | 0.8919 | 0.8935 | 29.95 |
| Improved Transformer | 0.9046 | 0.9044 | 0.9052 | 0.9057 | 158.52 |
| SE Transformer | 0.9009 | 0.9001 | 0.9013 | 0.9011 | 200.69 |
| Windowed Transformer | 0.8975 | 0.8973 | 0.8974 | 0.8984 | 182.48 |

---

## üîç –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ (–∫–ª—é—á–µ–≤—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è)

–ù–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏ —É Transformer-–ø–æ–¥—Ö–æ–¥–æ–≤ ‚Äî –º–µ–∂–¥—É:
- `SITTING` ‚Üî `STANDING`
- `WALKING` ‚Üî `WALKING_UPSTAIRS/WALKING_DOWNSTAIRS`

–ü—Ä–∏—á–∏–Ω—ã:
1. **–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –±–ª–∏–∑–æ—Å—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤** (–æ—Å–æ–±–µ–Ω–Ω–æ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–∑—ã).
2. **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ—Å—Ç—å –æ–∫–Ω–∞ 128**: –º–æ–∂–µ—Ç –Ω–µ —Ö–≤–∞—Ç–∞—Ç—å –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
3. **Domain gap –º–µ–∂–¥—É val –∏ test**: –≤—ã—Å–æ–∫–∏–µ val-–º–µ—Ç—Ä–∏–∫–∏ –Ω–µ –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è –Ω–∞ test –ø—Ä–∏ —É—Å–∏–ª–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏.

---

##  –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã

1. **–õ—É—á—à–∏–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —ç—Ç–æ–π –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–µ –ø–æ–∫–∞–∑–∞–ª baseline Logistic Regression**  
   (–∏ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É, –∏ –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏).

2. Transformer-–º–æ–¥–µ–ª–∏ –Ω–∞ —Å—ã—Ä—ã—Ö –æ–∫–Ω–∞—Ö —É–ª—É—á—à–∞—é—Ç—Å—è –ø—Ä–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–º —É—Å–ª–æ–∂–Ω–µ–Ω–∏–∏,  
   –Ω–æ **–Ω–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç baseline** –Ω–∞ UCI HAR –≤ —Ç–µ–∫—É—â–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª–µ.

3. SE –∏ Windowed attention –¥–∞–ª–∏ –ø–æ–ª–µ–∑–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã:
   - –ª—É—á—à–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏,
   - –Ω–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –ø—Ä–∏—Ä–æ—Å—Ç/–ø—Ä–æ—Å–∞–¥–∫–∞ –Ω–∞ test,
   - –∑–∞–º–µ—Ç–Ω–æ –±–æ–ª—å—à–∏–π compute cost.

4. –î–ª—è Colab Free baseline –æ—Å—Ç–∞—ë—Ç—Å—è —Å–∏–ª—å–Ω—ã–º –∏ —Ä–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º —Ä–µ—à–µ–Ω–∏–µ–º,  
   –∞ Transformer-–ª–∏–Ω–∏—è ‚Äî —Ö–æ—Ä–æ—à–∞—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –≤–µ—Ç–∫–∞ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ç—é–Ω–∏–Ω–≥–∞.

---

## –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å

## 1. –û—Ç–∫—Ä—ã—Ç—å –Ω–æ—É—Ç–±—É–∫ –≤ Google Colab
- –ó–∞–≥—Ä—É–∑–∏—Ç–µ `.ipynb` –≤ Colab –∏–ª–∏ –æ—Ç–∫—Ä–æ–π—Ç–µ –∏–∑ GitHub.
- [–°—Å—ã–ª–∫–∞ –Ω–∞ –±–ª–æ–∫–Ω–æ—Ç](https://colab.research.google.com/drive/1XZcSfYYNdfnMorUk0SzNVqnWAowrBaNg?usp=sharing)

## 2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
–û–±—ã—á–Ω–æ –≤ Colab —É–∂–µ –µ—Å—Ç—å –±–æ–ª—å—à–∞—è —á–∞—Å—Ç—å –ø–∞–∫–µ—Ç–æ–≤. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏:

```bash
pip install -U torch torchvision torchaudio scikit-learn pandas numpy matplotlib seaborn

```

## 3. –ó–∞–ø—É—Å—Ç–∏—Ç—å —è—á–µ–π–∫–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É

–í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å

–í –Ω–æ—É—Ç–±—É–∫–µ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è reproducibility_dump —Å:

- seed,

- –≤–µ—Ä—Å–∏–µ–π –±–∏–±–ª–∏–æ—Ç–µ–∫,

- –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞,

- –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏,

- –ª—É—á—à–∏–º–∏ checkpoint‚Äô–∞–º–∏,

- –≤—Ä–µ–º–µ–Ω–µ–º –æ–±—É—á–µ–Ω–∏—è,

- –∏—Ç–æ–≥–æ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏.